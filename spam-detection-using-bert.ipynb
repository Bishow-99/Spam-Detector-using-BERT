{
 "cells": [
  {
   "attachments": {
    "fd91d119-0398-4da1-8681-8ca675dd13a5.jfif": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color:black;font-size:30px;text-align:center'> Introduction</h1>\n",
    "\n",
    "Spam detection is the process of detecting the spam or fake messages from our email. For this application, I have use deep learning technique and Google bert transformer to find whether our email contains spam or not. For validation purpose, I have used few messages from my email to identify or test whether my model is working properly or not. The dataset which I have used in this notebook is Kaggle Email spam dataset.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![images.jfif](attachment:fd91d119-0398-4da1-8681-8ca675dd13a5.jfif)\n",
    "\n",
    "\n",
    "Note: Although I have validate this model with my spam or not spam email and also giving excellent accuracy, but, I request others not to deploy this model for their personal product because this dataset is small in size however you can use this method for building new model in large dataset and also you can gain a huge knowledge how to play with bert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:47:42.242390Z",
     "iopub.status.busy": "2022-08-29T04:47:42.241966Z",
     "iopub.status.idle": "2022-08-29T04:47:42.248146Z",
     "shell.execute_reply": "2022-08-29T04:47:42.246765Z",
     "shell.execute_reply.started": "2022-08-29T04:47:42.242359Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:47:44.688450Z",
     "iopub.status.busy": "2022-08-29T04:47:44.688081Z",
     "iopub.status.idle": "2022-08-29T04:47:44.718698Z",
     "shell.execute_reply": "2022-08-29T04:47:44.717633Z",
     "shell.execute_reply.started": "2022-08-29T04:47:44.688419Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('Email_spam.csv',encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:47:47.163048Z",
     "iopub.status.busy": "2022-08-29T04:47:47.161912Z",
     "iopub.status.idle": "2022-08-29T04:47:47.184934Z",
     "shell.execute_reply": "2022-08-29T04:47:47.183876Z",
     "shell.execute_reply.started": "2022-08-29T04:47:47.163006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:47:50.119275Z",
     "iopub.status.busy": "2022-08-29T04:47:50.118905Z",
     "iopub.status.idle": "2022-08-29T04:47:50.143548Z",
     "shell.execute_reply": "2022-08-29T04:47:50.141888Z",
     "shell.execute_reply.started": "2022-08-29T04:47:50.119244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five feature where only two are useful to build my model so I am going to drop last three features name as Unamed:2, Unamed:3, Unamed:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:47:54.459977Z",
     "iopub.status.busy": "2022-08-29T04:47:54.459272Z",
     "iopub.status.idle": "2022-08-29T04:47:54.466546Z",
     "shell.execute_reply": "2022-08-29T04:47:54.465005Z",
     "shell.execute_reply.started": "2022-08-29T04:47:54.459940Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(df.iloc[:,2:],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:47:55.716414Z",
     "iopub.status.busy": "2022-08-29T04:47:55.716039Z",
     "iopub.status.idle": "2022-08-29T04:47:55.730895Z",
     "shell.execute_reply": "2022-08-29T04:47:55.729870Z",
     "shell.execute_reply.started": "2022-08-29T04:47:55.716382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:47:57.605637Z",
     "iopub.status.busy": "2022-08-29T04:47:57.605262Z",
     "iopub.status.idle": "2022-08-29T04:47:57.615735Z",
     "shell.execute_reply": "2022-08-29T04:47:57.614605Z",
     "shell.execute_reply.started": "2022-08-29T04:47:57.605605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1    0\n",
       "v2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:47:59.486570Z",
     "iopub.status.busy": "2022-08-29T04:47:59.485566Z",
     "iopub.status.idle": "2022-08-29T04:47:59.492448Z",
     "shell.execute_reply": "2022-08-29T04:47:59.491035Z",
     "shell.execute_reply.started": "2022-08-29T04:47:59.486528Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'v1':'label','v2':'message'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:48:01.336096Z",
     "iopub.status.busy": "2022-08-29T04:48:01.335350Z",
     "iopub.status.idle": "2022-08-29T04:48:01.350620Z",
     "shell.execute_reply": "2022-08-29T04:48:01.349728Z",
     "shell.execute_reply.started": "2022-08-29T04:48:01.336059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To count the number of spam or not spam message in our dataset we use this technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:48:04.171924Z",
     "iopub.status.busy": "2022-08-29T04:48:04.171557Z",
     "iopub.status.idle": "2022-08-29T04:48:04.179516Z",
     "shell.execute_reply": "2022-08-29T04:48:04.178359Z",
     "shell.execute_reply.started": "2022-08-29T04:48:04.171894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of spam and not spam message in our dataset is\n",
      " ham     4825\n",
      "spam     747\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('The total number of spam and not spam message in our dataset is\\n',df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:48:05.331607Z",
     "iopub.status.busy": "2022-08-29T04:48:05.331218Z",
     "iopub.status.idle": "2022-08-29T04:48:06.051354Z",
     "shell.execute_reply": "2022-08-29T04:48:06.050433Z",
     "shell.execute_reply.started": "2022-08-29T04:48:05.331576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, The main reason to use ktrain is that ktrain comes with integrated bert function which makes our work more easier to build our model. Moreover, ktrain is a lightweight wrapper library for TensorFlow Keras. It can be very helpful in building projects consisting of neural networks. Using this wrapper, we can build, train and deploy deep learning and machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:50:12.970607Z",
     "iopub.status.busy": "2022-08-29T04:50:12.969483Z",
     "iopub.status.idle": "2022-08-29T04:50:14.699024Z",
     "shell.execute_reply": "2022-08-29T04:50:14.697550Z",
     "shell.execute_reply.started": "2022-08-29T04:50:12.970553Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am splitting my dataset for training and testing purpose, wheree 90% of data are used in training purpose where onyly 10% of data from the\n",
    "same dataset is apply for testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:50:20.877197Z",
     "iopub.status.busy": "2022-08-29T04:50:20.876789Z",
     "iopub.status.idle": "2022-08-29T04:50:20.884382Z",
     "shell.execute_reply": "2022-08-29T04:50:20.883304Z",
     "shell.execute_reply.started": "2022-08-29T04:50:20.877160Z"
    }
   },
   "outputs": [],
   "source": [
    "split=int(len(df)*0.90)\n",
    "train_data=df.iloc[:split,:]\n",
    "test_data=df.iloc[split:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:50:21.750239Z",
     "iopub.status.busy": "2022-08-29T04:50:21.749875Z",
     "iopub.status.idle": "2022-08-29T04:50:21.766381Z",
     "shell.execute_reply": "2022-08-29T04:50:21.763616Z",
     "shell.execute_reply.started": "2022-08-29T04:50:21.750208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>ham</td>\n",
       "      <td>By the way, 'rencontre' is to meet again. Moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have WON a guaranteed å£1000 cash or a å£2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>ham</td>\n",
       "      <td>U attend ur driving lesson how many times a wk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>ham</td>\n",
       "      <td>Uncle G, just checking up on you. Do have a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hello boytoy ! Geeee ... I'm missing you today...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5014 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5009   ham  By the way, 'rencontre' is to meet again. Moun...\n",
       "5010  spam  You have WON a guaranteed å£1000 cash or a å£2...\n",
       "5011   ham  U attend ur driving lesson how many times a wk...\n",
       "5012   ham  Uncle G, just checking up on you. Do have a re...\n",
       "5013   ham  Hello boytoy ! Geeee ... I'm missing you today...\n",
       "\n",
       "[5014 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black;font-size:30px;text-align:center\"> Lets fine tune our BERT model</h1>\n",
    "\n",
    "text_from_df ktrain perform preprocessing of data from dataframe and will return five variables out of it these variables are (x_train,y_train)(x_test,y_test) and preprocess. The arguments inside text_from_df are: train_df is the dataset that are used for training the model, text_column is  text column present in dataframe, label_columns is our traget/output column present in the dataset. maxlen maximum length of word that can be present inside a sentence in case of BERT we can taken maximum length of 512 if we will take sentence length beyond 512 it will give error,however our dataset is small so I have used only maxlen as 400. preprocess_mode this says how the preprocessing has been done, in my case i have preprocessed the textual data using BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:50:50.419239Z",
     "iopub.status.busy": "2022-08-29T04:50:50.418320Z",
     "iopub.status.idle": "2022-08-29T04:50:52.426799Z",
     "shell.execute_reply": "2022-08-29T04:50:52.425876Z",
     "shell.execute_reply.started": "2022-08-29T04:50:50.419192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', 'spam']\n",
      "   ham  spam\n",
      "0  1.0   0.0\n",
      "1  1.0   0.0\n",
      "2  0.0   1.0\n",
      "3  1.0   0.0\n",
      "4  1.0   0.0\n",
      "['ham', 'spam']\n",
      "      ham  spam\n",
      "5014  1.0   0.0\n",
      "5015  1.0   0.0\n",
      "5016  0.0   1.0\n",
      "5017  1.0   0.0\n",
      "5018  1.0   0.0\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test),preprocess=text.texts_from_df(train_df=train_data,\n",
    "                text_column='message',label_columns='label',\n",
    "                   val_df=test_data,maxlen=300,preprocess_mode='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:50:56.419400Z",
     "iopub.status.busy": "2022-08-29T04:50:56.418736Z",
     "iopub.status.idle": "2022-08-29T04:50:56.430786Z",
     "shell.execute_reply": "2022-08-29T04:50:56.429733Z",
     "shell.execute_reply.started": "2022-08-29T04:50:56.419363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5014, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:51:00.857288Z",
     "iopub.status.busy": "2022-08-29T04:51:00.856919Z",
     "iopub.status.idle": "2022-08-29T04:51:00.864476Z",
     "shell.execute_reply": "2022-08-29T04:51:00.863375Z",
     "shell.execute_reply.started": "2022-08-29T04:51:00.857256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:51:02.598641Z",
     "iopub.status.busy": "2022-08-29T04:51:02.598248Z",
     "iopub.status.idle": "2022-08-29T04:51:02.607259Z",
     "shell.execute_reply": "2022-08-29T04:51:02.606010Z",
     "shell.execute_reply.started": "2022-08-29T04:51:02.598607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 101, 2175, 2127, ...,    0,    0,    0],\n",
       "        [ 101, 7929, 2474, ...,    0,    0,    0],\n",
       "        [ 101, 2489, 4443, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 1057, 5463, ...,    0,    0,    0],\n",
       "        [ 101, 4470, 1043, ...,    0,    0,    0],\n",
       "        [ 101, 7592, 2879, ...,    0,    0,    0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create bert model we use text_classifier with the help of keras ktrain library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:51:06.144184Z",
     "iopub.status.busy": "2022-08-29T04:51:06.142809Z",
     "iopub.status.idle": "2022-08-29T04:51:13.931721Z",
     "shell.execute_reply": "2022-08-29T04:51:13.930633Z",
     "shell.execute_reply.started": "2022-08-29T04:51:06.144130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 300\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model=text.text_classifier(name='bert',train_data=(X_train,y_train),preproc=preprocess,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-28T13:15:14.417954Z",
     "iopub.status.busy": "2022-08-28T13:15:14.417236Z",
     "iopub.status.idle": "2022-08-28T13:15:14.426172Z",
     "shell.execute_reply": "2022-08-28T13:15:14.424639Z",
     "shell.execute_reply.started": "2022-08-28T13:15:14.417910Z"
    }
   },
   "source": [
    "Now, we will use get_learner which will wrap the model and data and helps us to used for final prediction of result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input-Token (InputLayer)       [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " Input-Segment (InputLayer)     [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " Embedding-Token (TokenEmbeddin  [(None, 300, 768),  23440896    ['Input-Token[0][0]']            \n",
      " g)                              (30522, 768)]                                                    \n",
      "                                                                                                  \n",
      " Embedding-Segment (Embedding)  (None, 300, 768)     1536        ['Input-Segment[0][0]']          \n",
      "                                                                                                  \n",
      " Embedding-Token-Segment (Add)  (None, 300, 768)     0           ['Embedding-Token[0][0]',        \n",
      "                                                                  'Embedding-Segment[0][0]']      \n",
      "                                                                                                  \n",
      " Embedding-Position (PositionEm  (None, 300, 768)    230400      ['Embedding-Token-Segment[0][0]']\n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " Embedding-Dropout (Dropout)    (None, 300, 768)     0           ['Embedding-Position[0][0]']     \n",
      "                                                                                                  \n",
      " Embedding-Norm (LayerNormaliza  (None, 300, 768)    1536        ['Embedding-Dropout[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, 300, 768)    2362368     ['Embedding-Norm[0][0]']         \n",
      " on (MultiHeadAttention)                                                                          \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Embedding-Norm[0][0]',         \n",
      " on-Add (Add)                                                     'Encoder-1-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-1-MultiHeadSelfAttenti  (None, 300, 768)    1536        ['Encoder-1-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward (FeedFor  (None, 300, 768)    4722432     ['Encoder-1-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Dropout   (None, 300, 768)    0           ['Encoder-1-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Add (Add  (None, 300, 768)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-1-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-1-FeedForward-Norm (La  (None, 300, 768)    1536        ['Encoder-1-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, 300, 768)    2362368     ['Encoder-1-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-1-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-2-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-2-MultiHeadSelfAttenti  (None, 300, 768)    1536        ['Encoder-2-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward (FeedFor  (None, 300, 768)    4722432     ['Encoder-2-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Dropout   (None, 300, 768)    0           ['Encoder-2-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Add (Add  (None, 300, 768)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-2-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-2-FeedForward-Norm (La  (None, 300, 768)    1536        ['Encoder-2-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, 300, 768)    2362368     ['Encoder-2-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-3-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-2-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-3-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-3-MultiHeadSelfAttenti  (None, 300, 768)    1536        ['Encoder-3-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward (FeedFor  (None, 300, 768)    4722432     ['Encoder-3-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Dropout   (None, 300, 768)    0           ['Encoder-3-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Add (Add  (None, 300, 768)    0           ['Encoder-3-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-3-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-3-FeedForward-Norm (La  (None, 300, 768)    1536        ['Encoder-3-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, 300, 768)    2362368     ['Encoder-3-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-4-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-3-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-4-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-4-MultiHeadSelfAttenti  (None, 300, 768)    1536        ['Encoder-4-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward (FeedFor  (None, 300, 768)    4722432     ['Encoder-4-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Dropout   (None, 300, 768)    0           ['Encoder-4-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Add (Add  (None, 300, 768)    0           ['Encoder-4-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-4-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-4-FeedForward-Norm (La  (None, 300, 768)    1536        ['Encoder-4-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, 300, 768)    2362368     ['Encoder-4-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-5-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-4-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-5-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-5-MultiHeadSelfAttenti  (None, 300, 768)    1536        ['Encoder-5-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward (FeedFor  (None, 300, 768)    4722432     ['Encoder-5-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward-Dropout   (None, 300, 768)    0           ['Encoder-5-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward-Add (Add  (None, 300, 768)    0           ['Encoder-5-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-5-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-5-FeedForward-Norm (La  (None, 300, 768)    1536        ['Encoder-5-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, 300, 768)    2362368     ['Encoder-5-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-6-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-5-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-6-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-6-MultiHeadSelfAttenti  (None, 300, 768)    1536        ['Encoder-6-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward (FeedFor  (None, 300, 768)    4722432     ['Encoder-6-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward-Dropout   (None, 300, 768)    0           ['Encoder-6-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward-Add (Add  (None, 300, 768)    0           ['Encoder-6-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-6-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-6-FeedForward-Norm (La  (None, 300, 768)    1536        ['Encoder-6-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, 300, 768)    2362368     ['Encoder-6-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-7-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-6-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-7-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-7-MultiHeadSelfAttenti  (None, 300, 768)    1536        ['Encoder-7-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward (FeedFor  (None, 300, 768)    4722432     ['Encoder-7-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward-Dropout   (None, 300, 768)    0           ['Encoder-7-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward-Add (Add  (None, 300, 768)    0           ['Encoder-7-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-7-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-7-FeedForward-Norm (La  (None, 300, 768)    1536        ['Encoder-7-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, 300, 768)    2362368     ['Encoder-7-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-8-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-7-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-8-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-8-MultiHeadSelfAttenti  (None, 300, 768)    1536        ['Encoder-8-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward (FeedFor  (None, 300, 768)    4722432     ['Encoder-8-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward-Dropout   (None, 300, 768)    0           ['Encoder-8-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward-Add (Add  (None, 300, 768)    0           ['Encoder-8-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-8-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-8-FeedForward-Norm (La  (None, 300, 768)    1536        ['Encoder-8-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-9-MultiHeadSelfAttenti  (None, 300, 768)    2362368     ['Encoder-8-FeedForward-Norm[0][0\n",
      " on (MultiHeadAttention)                                         ]']                              \n",
      "                                                                                                  \n",
      " Encoder-9-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-9-MultiHeadSelfAttentio\n",
      " on-Dropout (Dropout)                                            n[0][0]']                        \n",
      "                                                                                                  \n",
      " Encoder-9-MultiHeadSelfAttenti  (None, 300, 768)    0           ['Encoder-8-FeedForward-Norm[0][0\n",
      " on-Add (Add)                                                    ]',                              \n",
      "                                                                  'Encoder-9-MultiHeadSelfAttentio\n",
      "                                                                 n-Dropout[0][0]']                \n",
      "                                                                                                  \n",
      " Encoder-9-MultiHeadSelfAttenti  (None, 300, 768)    1536        ['Encoder-9-MultiHeadSelfAttentio\n",
      " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
      "                                                                                                  \n",
      " Encoder-9-FeedForward (FeedFor  (None, 300, 768)    4722432     ['Encoder-9-MultiHeadSelfAttentio\n",
      " ward)                                                           n-Norm[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-9-FeedForward-Dropout   (None, 300, 768)    0           ['Encoder-9-FeedForward[0][0]']  \n",
      " (Dropout)                                                                                        \n",
      "                                                                                                  \n",
      " Encoder-9-FeedForward-Add (Add  (None, 300, 768)    0           ['Encoder-9-MultiHeadSelfAttentio\n",
      " )                                                               n-Norm[0][0]',                   \n",
      "                                                                  'Encoder-9-FeedForward-Dropout[0\n",
      "                                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " Encoder-9-FeedForward-Norm (La  (None, 300, 768)    1536        ['Encoder-9-FeedForward-Add[0][0]\n",
      " yerNormalization)                                               ']                               \n",
      "                                                                                                  \n",
      " Encoder-10-MultiHeadSelfAttent  (None, 300, 768)    2362368     ['Encoder-9-FeedForward-Norm[0][0\n",
      " ion (MultiHeadAttention)                                        ]']                              \n",
      "                                                                                                  \n",
      " Encoder-10-MultiHeadSelfAttent  (None, 300, 768)    0           ['Encoder-10-MultiHeadSelfAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Encoder-10-MultiHeadSelfAttent  (None, 300, 768)    0           ['Encoder-9-FeedForward-Norm[0][0\n",
      " ion-Add (Add)                                                   ]',                              \n",
      "                                                                  'Encoder-10-MultiHeadSelfAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Encoder-10-MultiHeadSelfAttent  (None, 300, 768)    1536        ['Encoder-10-MultiHeadSelfAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-10-FeedForward (FeedFo  (None, 300, 768)    4722432     ['Encoder-10-MultiHeadSelfAttenti\n",
      " rward)                                                          on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Encoder-10-FeedForward-Dropout  (None, 300, 768)    0           ['Encoder-10-FeedForward[0][0]'] \n",
      "  (Dropout)                                                                                       \n",
      "                                                                                                  \n",
      " Encoder-10-FeedForward-Add (Ad  (None, 300, 768)    0           ['Encoder-10-MultiHeadSelfAttenti\n",
      " d)                                                              on-Norm[0][0]',                  \n",
      "                                                                  'Encoder-10-FeedForward-Dropout[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Encoder-10-FeedForward-Norm (L  (None, 300, 768)    1536        ['Encoder-10-FeedForward-Add[0][0\n",
      " ayerNormalization)                                              ]']                              \n",
      "                                                                                                  \n",
      " Encoder-11-MultiHeadSelfAttent  (None, 300, 768)    2362368     ['Encoder-10-FeedForward-Norm[0][\n",
      " ion (MultiHeadAttention)                                        0]']                             \n",
      "                                                                                                  \n",
      " Encoder-11-MultiHeadSelfAttent  (None, 300, 768)    0           ['Encoder-11-MultiHeadSelfAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Encoder-11-MultiHeadSelfAttent  (None, 300, 768)    0           ['Encoder-10-FeedForward-Norm[0][\n",
      " ion-Add (Add)                                                   0]',                             \n",
      "                                                                  'Encoder-11-MultiHeadSelfAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Encoder-11-MultiHeadSelfAttent  (None, 300, 768)    1536        ['Encoder-11-MultiHeadSelfAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-11-FeedForward (FeedFo  (None, 300, 768)    4722432     ['Encoder-11-MultiHeadSelfAttenti\n",
      " rward)                                                          on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Encoder-11-FeedForward-Dropout  (None, 300, 768)    0           ['Encoder-11-FeedForward[0][0]'] \n",
      "  (Dropout)                                                                                       \n",
      "                                                                                                  \n",
      " Encoder-11-FeedForward-Add (Ad  (None, 300, 768)    0           ['Encoder-11-MultiHeadSelfAttenti\n",
      " d)                                                              on-Norm[0][0]',                  \n",
      "                                                                  'Encoder-11-FeedForward-Dropout[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Encoder-11-FeedForward-Norm (L  (None, 300, 768)    1536        ['Encoder-11-FeedForward-Add[0][0\n",
      " ayerNormalization)                                              ]']                              \n",
      "                                                                                                  \n",
      " Encoder-12-MultiHeadSelfAttent  (None, 300, 768)    2362368     ['Encoder-11-FeedForward-Norm[0][\n",
      " ion (MultiHeadAttention)                                        0]']                             \n",
      "                                                                                                  \n",
      " Encoder-12-MultiHeadSelfAttent  (None, 300, 768)    0           ['Encoder-12-MultiHeadSelfAttenti\n",
      " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
      "                                                                                                  \n",
      " Encoder-12-MultiHeadSelfAttent  (None, 300, 768)    0           ['Encoder-11-FeedForward-Norm[0][\n",
      " ion-Add (Add)                                                   0]',                             \n",
      "                                                                  'Encoder-12-MultiHeadSelfAttenti\n",
      "                                                                 on-Dropout[0][0]']               \n",
      "                                                                                                  \n",
      " Encoder-12-MultiHeadSelfAttent  (None, 300, 768)    1536        ['Encoder-12-MultiHeadSelfAttenti\n",
      " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
      "                                                                                                  \n",
      " Encoder-12-FeedForward (FeedFo  (None, 300, 768)    4722432     ['Encoder-12-MultiHeadSelfAttenti\n",
      " rward)                                                          on-Norm[0][0]']                  \n",
      "                                                                                                  \n",
      " Encoder-12-FeedForward-Dropout  (None, 300, 768)    0           ['Encoder-12-FeedForward[0][0]'] \n",
      "  (Dropout)                                                                                       \n",
      "                                                                                                  \n",
      " Encoder-12-FeedForward-Add (Ad  (None, 300, 768)    0           ['Encoder-12-MultiHeadSelfAttenti\n",
      " d)                                                              on-Norm[0][0]',                  \n",
      "                                                                  'Encoder-12-FeedForward-Dropout[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Encoder-12-FeedForward-Norm (L  (None, 300, 768)    1536        ['Encoder-12-FeedForward-Add[0][0\n",
      " ayerNormalization)                                              ]']                              \n",
      "                                                                                                  \n",
      " Extract (Extract)              (None, 768)          0           ['Encoder-12-FeedForward-Norm[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " NSP-Dense (Dense)              (None, 768)          590592      ['Extract[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            1538        ['NSP-Dense[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,320,962\n",
      "Trainable params: 109,320,962\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:52:05.575308Z",
     "iopub.status.busy": "2022-08-29T04:52:05.574571Z",
     "iopub.status.idle": "2022-08-29T04:52:06.710568Z",
     "shell.execute_reply": "2022-08-29T04:52:06.709589Z",
     "shell.execute_reply.started": "2022-08-29T04:52:05.575262Z"
    }
   },
   "outputs": [],
   "source": [
    "learner=ktrain.get_learner(model=model,train_data=(X_train,y_train),val_data=(X_test,y_test),batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6 style=\"color:black;font-size:30px;text-align:center\">How to find good learning rate?</h6>\n",
    "Here, giving learning rate and epochs are hypermeter so choose wisely in order to get better accuracy\n",
    "\n",
    "\n",
    "\n",
    "learner.lr_find() ->  find optimal learning rate\n",
    "\n",
    "learner.lr_plot() -> visually identify best learning rate\n",
    "\n",
    "so look this document  https://github.com/amaiya/ktrain to know more about the ktrain library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T04:52:10.231441Z",
     "iopub.status.busy": "2022-08-29T04:52:10.231069Z",
     "iopub.status.idle": "2022-08-29T04:57:58.754508Z",
     "shell.execute_reply": "2022-08-29T04:57:58.753400Z",
     "shell.execute_reply.started": "2022-08-29T04:52:10.231408Z"
    }
   },
   "outputs": [],
   "source": [
    "# learner.lr_find()\n",
    "# learner.lr_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T05:07:35.928372Z",
     "iopub.status.busy": "2022-08-29T05:07:35.927660Z",
     "iopub.status.idle": "2022-08-29T05:12:16.910783Z",
     "shell.execute_reply": "2022-08-29T05:12:16.909538Z",
     "shell.execute_reply.started": "2022-08-29T05:07:35.928337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 0.001...\n",
      "5014/5014 [==============================] - 1126s 223ms/step - loss: 0.4758 - accuracy: 0.8492 - val_loss: 0.3886 - val_accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243dec224c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " learner.fit_onecycle(lr=1e-3,epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In order to predict the new unlabeled data we can use get_predictor method in ktrain library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T05:37:11.512403Z",
     "iopub.status.busy": "2022-08-29T05:37:11.512050Z",
     "iopub.status.idle": "2022-08-29T05:37:11.517395Z",
     "shell.execute_reply": "2022-08-29T05:37:11.516085Z",
     "shell.execute_reply.started": "2022-08-29T05:37:11.512373Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor=ktrain.get_predictor(learner.model,preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T05:37:15.217648Z",
     "iopub.status.busy": "2022-08-29T05:37:15.217276Z",
     "iopub.status.idle": "2022-08-29T05:37:15.223267Z",
     "shell.execute_reply": "2022-08-29T05:37:15.222314Z",
     "shell.execute_reply.started": "2022-08-29T05:37:15.217615Z"
    }
   },
   "outputs": [],
   "source": [
    "new_message=['CONGRATULATIONS! You are the lucky online winner of a brand new Sweepstakes Craftsman Tool Shed entry!',\n",
    "         \n",
    "                  'Thank you again for your interest in the Associate Data Scientist position in our company, and for your cooperation in the interview process so far',\n",
    "             \n",
    "              ' Fidelity Life - $250K in life insurance for as low as $15 a month! No Exam Option available',\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-29T05:47:41.596891Z",
     "iopub.status.busy": "2022-08-29T05:47:41.595882Z",
     "iopub.status.idle": "2022-08-29T05:47:45.152350Z",
     "shell.execute_reply": "2022-08-29T05:47:45.151356Z",
     "shell.execute_reply.started": "2022-08-29T05:47:41.596844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham', 'ham', 'ham']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:black;font-size:30px;text-align:center\"> Conclusion </h1>\n",
    "\n",
    "The model is not predicting that much correct while giving external messages due to less number of data and I am getting contiously out of memory problem although I am using 4gb graphics card so I have used only 1 batch_size. However if you want to see the my kaggle where my model is predicting the external data amazingly then click here <a href=\"https://www.kaggle.com/code/bishowlamsal/spam-detector-using-bert\"> Kaggle</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets save our model so that it can be use for deploy in application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.save('bert_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
